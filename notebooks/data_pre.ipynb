{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: fredapi in /opt/anaconda3/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from fredapi) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->fredapi) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->fredapi) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->fredapi) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->fredapi) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlrd in /opt/anaconda3/lib/python3.11/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas_ta in /opt/anaconda3/lib/python3.11/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from pandas_ta) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pandas_ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pandas_ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /opt/anaconda3/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: yfinance==0.2.54 in /opt/anaconda3/lib/python3.11/site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance==0.2.54) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.54) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance==0.2.54) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance==0.2.54) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance==0.2.54) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance==0.2.54) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance==0.2.54) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance==0.2.54) (2025.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance==0.2.54) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: yfinance in /opt/anaconda3/lib/python3.11/site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2025.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install  pandas\n",
    "%pip install fredapi\n",
    "%pip install xlrd\n",
    "%pip install pandas_ta\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install sklearn\n",
    "%pip install scikit-learn\n",
    "%pip install tensorflow\n",
    "%pip install --upgrade yfinance==0.2.54\n",
    "%pip install yfinance\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickers | Gold, Silver, Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gold...\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gold saved with shape: (6076, 12)\n",
      "Downloading Silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Silver saved with shape: (6078, 12)\n",
      "Downloading Copper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Copper saved with shape: (6081, 12)\n",
      "\n",
      "üîç Sample of Gold with features:\n",
      "Price             Open        High         Low       Close Volume       SMA_7  \\\n",
      "Ticker            GC=F        GC=F        GC=F        GC=F   GC=F               \n",
      "Date                                                                            \n",
      "2000-10-11  272.500000  273.500000  270.500000  270.500000     18  270.685713   \n",
      "2000-10-12  274.000000  276.399994  274.000000  276.399994      3  271.371425   \n",
      "2000-10-13  274.200012  274.200012  272.399994  272.399994      0  271.671426   \n",
      "2000-10-16  271.500000  271.500000  271.500000  271.500000      5  271.799997   \n",
      "2000-10-17  271.100006  271.100006  271.100006  271.100006      0  272.057142   \n",
      "\n",
      "Price           SMA_30     RSI_14      MACD  BB_Width Volume_Zscore Pct_Change  \n",
      "Ticker                                                                          \n",
      "Date                                                                            \n",
      "2000-10-11  272.929997  50.431059 -0.213476  9.002555     -0.206086  -0.006975  \n",
      "2000-10-12  273.013330  58.333324  0.177530  9.780844     -0.229487   0.021811  \n",
      "2000-10-13  272.816664  47.098960  0.162426  9.780995     -0.234134  -0.014472  \n",
      "2000-10-16  272.633330  46.000014  0.091038  9.773351     -0.226660  -0.003304  \n",
      "2000-10-17  272.476664  35.907373  0.019814  9.829710     -0.234298  -0.001473  \n"
     ]
    }
   ],
   "source": [
    "tickers = {\n",
    "    \"Gold\": \"GC=F\",\n",
    "    \"Silver\": \"SI=F\",\n",
    "    \"Copper\": \"HG=F\"\n",
    "}\n",
    "\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "\n",
    "data = {}\n",
    "for name, ticker in tickers.items():\n",
    "    print(f\"Downloading {name}...\")\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    df.dropna(inplace=True)\n",
    "    time.sleep(5)\n",
    "\n",
    "    df['SMA_7'] = df['Close'].rolling(window=7).mean()\n",
    "    df['SMA_30'] = df['Close'].rolling(window=30).mean()\n",
    "    \n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD calculation\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df['MACD'] = macd - signal\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    sma = df['Close'].rolling(window=20).mean()\n",
    "    std = df['Close'].rolling(window=20).std()\n",
    "    upper_band = sma + (std * 2)\n",
    "    lower_band = sma - (std * 2)\n",
    "    df['BB_Width'] = upper_band - lower_band\n",
    "    \n",
    "    # Volume Z-score and Percent Change\n",
    "    df['Volume_Zscore'] = (df['Volume'] - df['Volume'].rolling(30).mean()) / df['Volume'].rolling(30).std()\n",
    "    df['Pct_Change'] = df['Close'].pct_change()\n",
    "    \n",
    "    df.dropna(inplace=True)  # Drop any NaNs from rolling/indicators\n",
    "    data[name] = df\n",
    "    df.to_csv(f\"{name}_YF_2012_2024.csv\")\n",
    "    print(f\" {name} saved with shape: {df.shape}\")\n",
    "\n",
    "# Example output\n",
    "print(\"\\nüîç Sample of Gold with features:\")\n",
    "print(data[\"Gold\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLD YF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Downloading GLD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved to GLD_2012_2024_OHLCV.csv\n",
      "Price        GLD_Open   GLD_High    GLD_Low  GLD_Close GLD_Volume\n",
      "Ticker            GLD        GLD        GLD        GLD        GLD\n",
      "Date                                                             \n",
      "2004-11-18  44.430000  44.490002  44.070000  44.380001    5992000\n",
      "2004-11-19  44.490002  44.919998  44.470001  44.779999   11655300\n",
      "2004-11-22  44.750000  44.970001  44.740002  44.950001   11996000\n",
      "2004-11-23  44.880001  44.919998  44.720001  44.750000    3169200\n",
      "2004-11-24  44.930000  45.049999  44.790001  45.049999    6105100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download GLD data\n",
    "print(\" Downloading GLD...\")\n",
    "gld = yf.download(\"GLD\", start=\"2000-01-01\", end=\"2024-12-31\", interval=\"1d\")\n",
    "\n",
    "# Keep OHLCV and rename for clarity\n",
    "gld = gld[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].rename(columns={\n",
    "    \"Open\": \"GLD_Open\",\n",
    "    \"High\": \"GLD_High\",\n",
    "    \"Low\": \"GLD_Low\",\n",
    "    \"Close\": \"GLD_Close\",\n",
    "    \"Volume\": \"GLD_Volume\"\n",
    "})\n",
    "\n",
    "# Drop any missing values\n",
    "gld.dropna(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "gld.to_csv(\"GLD_2012_2024_OHLCV.csv\")\n",
    "\n",
    "# Preview\n",
    "print(\" Saved to GLD_2012_2024_OHLCV.csv\")\n",
    "print(gld.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/wrgs7dkx0h5ftr4gsr51y6xm0000gn/T/ipykernel_37660/3680640131.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  gc_df = pd.read_csv(\"Gold_YF_2012_2024.csv\", index_col=0, parse_dates=True)\n",
      "/var/folders/j5/wrgs7dkx0h5ftr4gsr51y6xm0000gn/T/ipykernel_37660/3680640131.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  gld_df = pd.read_csv(\"GLD_2012_2024_OHLCV.csv\", index_col=0, parse_dates=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>BB_Width</th>\n",
       "      <th>Volume_Zscore</th>\n",
       "      <th>Pct_Change</th>\n",
       "      <th>GLD_Open</th>\n",
       "      <th>GLD_High</th>\n",
       "      <th>GLD_Low</th>\n",
       "      <th>GLD_Close</th>\n",
       "      <th>GLD_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>GC=F</td>\n",
       "      <td>GC=F</td>\n",
       "      <td>GC=F</td>\n",
       "      <td>GC=F</td>\n",
       "      <td>GC=F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GLD</td>\n",
       "      <td>GLD</td>\n",
       "      <td>GLD</td>\n",
       "      <td>GLD</td>\n",
       "      <td>GLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-11</th>\n",
       "      <td>272.5</td>\n",
       "      <td>273.5</td>\n",
       "      <td>270.5</td>\n",
       "      <td>270.5</td>\n",
       "      <td>18</td>\n",
       "      <td>270.685713</td>\n",
       "      <td>272.929997</td>\n",
       "      <td>50.431059</td>\n",
       "      <td>-0.213476</td>\n",
       "      <td>9.002555</td>\n",
       "      <td>-0.206086</td>\n",
       "      <td>-0.006975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-12</th>\n",
       "      <td>274.0</td>\n",
       "      <td>276.3999938964844</td>\n",
       "      <td>274.0</td>\n",
       "      <td>276.3999938964844</td>\n",
       "      <td>3</td>\n",
       "      <td>271.371425</td>\n",
       "      <td>273.013330</td>\n",
       "      <td>58.333324</td>\n",
       "      <td>0.177530</td>\n",
       "      <td>9.780844</td>\n",
       "      <td>-0.229487</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-13</th>\n",
       "      <td>274.20001220703125</td>\n",
       "      <td>274.20001220703125</td>\n",
       "      <td>272.3999938964844</td>\n",
       "      <td>272.3999938964844</td>\n",
       "      <td>0</td>\n",
       "      <td>271.671426</td>\n",
       "      <td>272.816664</td>\n",
       "      <td>47.098960</td>\n",
       "      <td>0.162426</td>\n",
       "      <td>9.780995</td>\n",
       "      <td>-0.234134</td>\n",
       "      <td>-0.014472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Open                High                Low  \\\n",
       "Price                                                                   \n",
       "Ticker                    GC=F                GC=F               GC=F   \n",
       "Date                       NaN                 NaN                NaN   \n",
       "2000-10-11               272.5               273.5              270.5   \n",
       "2000-10-12               274.0   276.3999938964844              274.0   \n",
       "2000-10-13  274.20001220703125  274.20001220703125  272.3999938964844   \n",
       "\n",
       "                        Close Volume       SMA_7      SMA_30     RSI_14  \\\n",
       "Price                                                                     \n",
       "Ticker                   GC=F   GC=F         NaN         NaN        NaN   \n",
       "Date                      NaN    NaN         NaN         NaN        NaN   \n",
       "2000-10-11              270.5     18  270.685713  272.929997  50.431059   \n",
       "2000-10-12  276.3999938964844      3  271.371425  273.013330  58.333324   \n",
       "2000-10-13  272.3999938964844      0  271.671426  272.816664  47.098960   \n",
       "\n",
       "                MACD  BB_Width  Volume_Zscore  Pct_Change GLD_Open GLD_High  \\\n",
       "Price                                                                         \n",
       "Ticker           NaN       NaN            NaN         NaN      GLD      GLD   \n",
       "Date             NaN       NaN            NaN         NaN      NaN      NaN   \n",
       "2000-10-11 -0.213476  9.002555      -0.206086   -0.006975      NaN      NaN   \n",
       "2000-10-12  0.177530  9.780844      -0.229487    0.021811      NaN      NaN   \n",
       "2000-10-13  0.162426  9.780995      -0.234134   -0.014472      NaN      NaN   \n",
       "\n",
       "           GLD_Low GLD_Close GLD_Volume  \n",
       "Price                                    \n",
       "Ticker         GLD       GLD        GLD  \n",
       "Date           NaN       NaN        NaN  \n",
       "2000-10-11     NaN       NaN        NaN  \n",
       "2000-10-12     NaN       NaN        NaN  \n",
       "2000-10-13     NaN       NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the newly uploaded files\n",
    "gc_df = pd.read_csv(\"Gold_YF_2012_2024.csv\", index_col=0, parse_dates=True)\n",
    "gld_df = pd.read_csv(\"GLD_2012_2024_OHLCV.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Merge the datasets on date index\n",
    "merged_df = gc_df.merge(gld_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Save the merged result\n",
    "merged_path = \"GCF_GLD.csv\"\n",
    "merged_df.to_csv(merged_path)\n",
    "\n",
    "# Show confirmation and preview\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRED Api | Macroeconomics indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CPI fetched successfully\n",
      " Unemployment_Rate fetched successfully\n",
      " Fed_Funds_Rate fetched successfully\n",
      " IPI fetched successfully\n",
      " M2 fetched successfully\n",
      " M1 fetched successfully\n",
      " Consumer_Sentiment fetched successfully\n",
      " 1Y_Treasury_Rate fetched successfully\n",
      " Housing_Starts fetched successfully\n",
      " House_Price_Index fetched successfully\n",
      " GDP_Quarterly fetched successfully\n",
      " Net_Exports_GS fetched successfully\n",
      " Balance_Trade fetched successfully\n"
     ]
    }
   ],
   "source": [
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize with your API key\n",
    "fred = Fred(api_key='c80af360488242f646f83131680c6c73')  # ‚Üê Replace with your actual FRED API key\n",
    "\n",
    "# Define date range\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "indicators = {\n",
    "    \"CPI\": \"CPIAUCSL\",                      # Consumer Price Index\n",
    "    \"Unemployment_Rate\": \"UNRATE\",         # Civilian Unemployment Rate\n",
    "    \"Fed_Funds_Rate\": \"FEDFUNDS\",          # Effective Federal Funds Rate\n",
    "    \"IPI\": \"INDPRO\",                        # Industrial Production Index\n",
    "    \"M2\": \"M2SL\",                           # Money Stock M2\n",
    "    \"M1\": \"M1SL\",                           # Money Stock M1\n",
    "    \"Consumer_Sentiment\": \"UMCSENT\",       # University of Michigan: Consumer Sentiment\n",
    "    \"1Y_Treasury_Rate\": \"GS1\",             # 1-Year Treasury Constant Maturity Rate\n",
    "    \"Housing_Starts\": \"HOUST\",             # Housing Starts: Total New Privately Owned\n",
    "    \"House_Price_Index\": \"USSTHPI\",        # U.S. All-Transactions House Price Index (quarterly)\n",
    "    \"GDP_Quarterly\": \"GDPC1\",              # Real GDP (Chained 2012 Dollars)\n",
    "    \"Net_Exports_GS\":\"NETEXP\",\n",
    "    \"Balance_Trade\": \"BOPGSTB\",\n",
    "}\n",
    "\n",
    "\n",
    "for name, code in indicators.items():\n",
    "    try:\n",
    "        data = fred.get_series(code, observation_start=start_date, observation_end=end_date)\n",
    "        print(f\" {name} fetched successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\" {name} ({code}) failed: {e}\")\n",
    "        \n",
    "        \n",
    "macro_data = {}\n",
    "for name, code in indicators.items():\n",
    "    series = fred.get_series(code, observation_start=start_date, observation_end=end_date)\n",
    "    df = pd.DataFrame(series, columns=[name])\n",
    "    df.index.name = \"Date\"\n",
    "    macro_data[name] = df\n",
    "\n",
    "# Combine and resample to daily using forward-fill\n",
    "macro_combined = pd.concat(macro_data.values(), axis=1)\n",
    "macro_combined = macro_combined.resample(\"D\").ffill()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTFC Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2012-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      As_of_Date_In_Form_YYMMDD         Market_and_Exchange_Names  \\\n",
      "56331                2015-12-29  SILVER - COMMODITY EXCHANGE INC.   \n",
      "56332                2015-12-22  SILVER - COMMODITY EXCHANGE INC.   \n",
      "56333                2015-12-15  SILVER - COMMODITY EXCHANGE INC.   \n",
      "56334                2015-12-08  SILVER - COMMODITY EXCHANGE INC.   \n",
      "56335                2015-12-01  SILVER - COMMODITY EXCHANGE INC.   \n",
      "\n",
      "       M_Money_Positions_Long_ALL  M_Money_Positions_Short_ALL  \\\n",
      "56331                       48386                        42104   \n",
      "56332                       48982                        39643   \n",
      "56333                       49552                        47917   \n",
      "56334                       51068                        43127   \n",
      "56335                       53313                        42866   \n",
      "\n",
      "       Open_Interest_All  Tot_Rept_Positions_Long_All  \\\n",
      "56331             179819                       154886   \n",
      "56332             177460                       154269   \n",
      "56333             184398                       159232   \n",
      "56334             179726                       154759   \n",
      "56335             179448                       154295   \n",
      "\n",
      "       Tot_Rept_Positions_Short_All  Swap_Positions_Long_All  \\\n",
      "56331                        164320                    27356   \n",
      "56332                        162381                    26934   \n",
      "56333                        167572                    29036   \n",
      "56334                        164794                    29076   \n",
      "56335                        162480                    29868   \n",
      "\n",
      "       Swap__Positions_Short_All  Change_in_M_Money_Long_All  \\\n",
      "56331                      33950                      -597.0   \n",
      "56332                      34488                      -570.0   \n",
      "56333                      33169                     -1516.0   \n",
      "56334                      35522                     -2245.0   \n",
      "56335                      35731                      1656.0   \n",
      "\n",
      "       Change_in_M_Money_Short_All  \n",
      "56331                       2462.0  \n",
      "56332                      -8274.0  \n",
      "56333                       4790.0  \n",
      "56334                        261.0  \n",
      "56335                         71.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Excel file\n",
    "cot_12_16_uf = pd.read_excel(\"raw_data/cot_12-16.xls\")\n",
    "\n",
    "# Filter for selected commodities\n",
    "selected_commodities = [\n",
    "    \"GOLD - COMMODITY EXCHANGE INC.\",\n",
    "    \"COPPER-GRADE #1 - COMMODITY EXCHANGE INC.\",\n",
    "    \"SILVER - COMMODITY EXCHANGE INC.\"\n",
    "]\n",
    "cot_12_16_uf = cot_12_16_uf[cot_12_16_uf['Market_and_Exchange_Names'].isin(selected_commodities)]\n",
    "\n",
    "# Convert the date column to datetime, coercing errors\n",
    "cot_12_16_uf[\"As_of_Date_In_Form_YYMMDD\"] = pd.to_datetime(\n",
    "    cot_12_16_uf[\"As_of_Date_In_Form_YYMMDD\"], format=\"%y%m%d\", errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Drop rows where the date conversion failed\n",
    "cot_12_16_uf = cot_12_16_uf.dropna(subset=[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "\n",
    "# Filter for data from 2012 to 2016\n",
    "cot_12_16_uf = cot_12_16_uf[\n",
    "    (cot_12_16_uf[\"As_of_Date_In_Form_YYMMDD\"] >= \"2012-01-01\") &\n",
    "    (cot_12_16_uf[\"As_of_Date_In_Form_YYMMDD\"] <= \"2016-12-31\")\n",
    "]\n",
    "\n",
    "# Keep only the columns you care about\n",
    "columns_to_keep = [\n",
    "    \"As_of_Date_In_Form_YYMMDD\",\n",
    "    \"Market_and_Exchange_Names\",\n",
    "    \"M_Money_Positions_Long_ALL\",\n",
    "    \"M_Money_Positions_Short_ALL\",\n",
    "    \"Open_Interest_All\",\n",
    "    \"Tot_Rept_Positions_Long_All\",\n",
    "    \"Tot_Rept_Positions_Short_All\",\n",
    "    \"Swap_Positions_Long_All\",\n",
    "    \"Swap__Positions_Short_All\",\n",
    "    \"Change_in_M_Money_Long_All\",\n",
    "    \"Change_in_M_Money_Short_All\"\n",
    "]\n",
    "\n",
    "cot_12_16 = cot_12_16_uf[columns_to_keep]\n",
    "\n",
    "# Save to CSV\n",
    "cot_12_16.to_csv(\"cot_2012_2015.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(cot_12_16.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Define your filters\n",
    "selected_commodities = [\n",
    "    \"GOLD - COMMODITY EXCHANGE INC.\",\n",
    "    \"SILVER - COMMODITY EXCHANGE INC.\",\n",
    "    \"COPPER - COMMODITY EXCHANGE INC.\",\n",
    "    \"COPPER- #1 - COMMODITY EXCHANGE INC.\",\n",
    "    \"COPPER-GRADE #1 - COMMODITY EXCHANGE INC.\"\n",
    "]\n",
    "\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"As_of_Date_In_Form_YYMMDD\",\n",
    "    \"Market_and_Exchange_Names\",\n",
    "    \"M_Money_Positions_Long_ALL\",\n",
    "    \"M_Money_Positions_Short_ALL\",\n",
    "    \"Open_Interest_All\",\n",
    "    \"Tot_Rept_Positions_Long_All\",\n",
    "    \"Tot_Rept_Positions_Short_All\",\n",
    "    \"Swap_Positions_Long_All\",\n",
    "    \"Swap__Positions_Short_All\",\n",
    "    \"Change_in_M_Money_Long_All\",\n",
    "    \"Change_in_M_Money_Short_All\"\n",
    "]\n",
    "\n",
    "# Find all .xls files matching your pattern\n",
    "file_list = glob.glob(\"raw_data/c_20*.xls\")  # Adjust path if needed\n",
    "\n",
    "# Container for all data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    print(f\"Processing: {file}\")\n",
    "    try:\n",
    "        df = pd.read_excel(file, engine=\"xlrd\")\n",
    "        \n",
    "        # Filter for selected commodities\n",
    "        df = df[df['Market_and_Exchange_Names'].isin(selected_commodities)]\n",
    "        \n",
    "        # Convert and clean date\n",
    "        df['As_of_Date_In_Form_YYMMDD'] = pd.to_datetime(\n",
    "            df['As_of_Date_In_Form_YYMMDD'], format='%y%m%d', errors='coerce'\n",
    "        )\n",
    "        df = df.dropna(subset=['As_of_Date_In_Form_YYMMDD'])\n",
    "\n",
    "        # Keep only selected columns\n",
    "        df = df[columns_to_keep]\n",
    "        \n",
    "        # Append to master dataframe\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {file}: {e}\")\n",
    "\n",
    "# Save final merged data\n",
    "combined_df.to_csv(\"cot_2016_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  As_of_Date_In_Form_YYMMDD                  Market_and_Exchange_Names  \\\n",
      "0                2012-01-03           SILVER - COMMODITY EXCHANGE INC.   \n",
      "1                2012-01-03             GOLD - COMMODITY EXCHANGE INC.   \n",
      "2                2012-01-03  COPPER-GRADE #1 - COMMODITY EXCHANGE INC.   \n",
      "3                2012-01-10           SILVER - COMMODITY EXCHANGE INC.   \n",
      "4                2012-01-10  COPPER-GRADE #1 - COMMODITY EXCHANGE INC.   \n",
      "\n",
      "   M_Money_Positions_Long_ALL  M_Money_Positions_Short_ALL  Open_Interest_All  \\\n",
      "0                       20325                        10709             142713   \n",
      "1                      128430                        17836             642722   \n",
      "2                       22625                        24636             120924   \n",
      "3                       20043                         8411             139861   \n",
      "4                       23792                        26257             126766   \n",
      "\n",
      "   Tot_Rept_Positions_Long_All  Tot_Rept_Positions_Short_All  \\\n",
      "0                       120423                        127385   \n",
      "1                       579460                        611450   \n",
      "2                       109878                        103641   \n",
      "3                       117141                        125925   \n",
      "4                       114584                        109526   \n",
      "\n",
      "   Swap_Positions_Long_All  Swap__Positions_Short_All  \\\n",
      "0                    23028                       9508   \n",
      "1                    49652                      67586   \n",
      "2                    51156                      10853   \n",
      "3                    20908                       9713   \n",
      "4                    51966                      11291   \n",
      "\n",
      "   Change_in_M_Money_Long_All  Change_in_M_Money_Short_All  \n",
      "0                      3102.0                       -314.0  \n",
      "1                      1437.0                       2763.0  \n",
      "2                       629.0                      -1378.0  \n",
      "3                      -282.0                      -2298.0  \n",
      "4                      1167.0                       1621.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs\n",
    "df1 = pd.read_csv(\"cot_2012_2015.csv\")\n",
    "df2 = pd.read_csv(\"cot_2016_2024.csv\")\n",
    "\n",
    "# Combine both datasets\n",
    "cot_2012_2024 = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Convert date column to datetime (if not already)\n",
    "cot_2012_2024[\"As_of_Date_In_Form_YYMMDD\"] = pd.to_datetime(cot_2012_2024[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "\n",
    "# Sort by date\n",
    "cot_2012_2024 = cot_2012_2024.sort_values(by=\"As_of_Date_In_Form_YYMMDD\").reset_index(drop=True)\n",
    "\n",
    "# Save to a new CSV\n",
    "cot_2012_2024.to_csv(\"cot_combined_2012_2024.csv\", index=False)\n",
    "\n",
    "# Preview the result\n",
    "print(cot_2012_2024.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commodity split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As_of_Date_In_Form_YYMMDD</th>\n",
       "      <th>Market_and_Exchange_Names</th>\n",
       "      <th>M_Money_Positions_Long_ALL</th>\n",
       "      <th>M_Money_Positions_Short_ALL</th>\n",
       "      <th>Open_Interest_All</th>\n",
       "      <th>Tot_Rept_Positions_Long_All</th>\n",
       "      <th>Tot_Rept_Positions_Short_All</th>\n",
       "      <th>Swap_Positions_Long_All</th>\n",
       "      <th>Swap__Positions_Short_All</th>\n",
       "      <th>Change_in_M_Money_Long_All</th>\n",
       "      <th>Change_in_M_Money_Short_All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>Gold</td>\n",
       "      <td>128430</td>\n",
       "      <td>17836</td>\n",
       "      <td>642722</td>\n",
       "      <td>579460</td>\n",
       "      <td>611450</td>\n",
       "      <td>49652</td>\n",
       "      <td>67586</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>2763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>Gold</td>\n",
       "      <td>126619</td>\n",
       "      <td>16120</td>\n",
       "      <td>644348</td>\n",
       "      <td>579825</td>\n",
       "      <td>614798</td>\n",
       "      <td>44445</td>\n",
       "      <td>70483</td>\n",
       "      <td>-1811.0</td>\n",
       "      <td>-1716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-01-17</td>\n",
       "      <td>Gold</td>\n",
       "      <td>129904</td>\n",
       "      <td>12926</td>\n",
       "      <td>667548</td>\n",
       "      <td>601279</td>\n",
       "      <td>639206</td>\n",
       "      <td>42442</td>\n",
       "      <td>63008</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>-3193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-01-24</td>\n",
       "      <td>Gold</td>\n",
       "      <td>138142</td>\n",
       "      <td>11205</td>\n",
       "      <td>663855</td>\n",
       "      <td>596340</td>\n",
       "      <td>634603</td>\n",
       "      <td>38033</td>\n",
       "      <td>61425</td>\n",
       "      <td>8238.0</td>\n",
       "      <td>-1721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>Gold</td>\n",
       "      <td>165702</td>\n",
       "      <td>6193</td>\n",
       "      <td>660852</td>\n",
       "      <td>595672</td>\n",
       "      <td>635564</td>\n",
       "      <td>24175</td>\n",
       "      <td>71649</td>\n",
       "      <td>27561.0</td>\n",
       "      <td>-5012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   As_of_Date_In_Form_YYMMDD Market_and_Exchange_Names  \\\n",
       "1                 2012-01-03                      Gold   \n",
       "5                 2012-01-10                      Gold   \n",
       "8                 2012-01-17                      Gold   \n",
       "9                 2012-01-24                      Gold   \n",
       "13                2012-01-31                      Gold   \n",
       "\n",
       "    M_Money_Positions_Long_ALL  M_Money_Positions_Short_ALL  \\\n",
       "1                       128430                        17836   \n",
       "5                       126619                        16120   \n",
       "8                       129904                        12926   \n",
       "9                       138142                        11205   \n",
       "13                      165702                         6193   \n",
       "\n",
       "    Open_Interest_All  Tot_Rept_Positions_Long_All  \\\n",
       "1              642722                       579460   \n",
       "5              644348                       579825   \n",
       "8              667548                       601279   \n",
       "9              663855                       596340   \n",
       "13             660852                       595672   \n",
       "\n",
       "    Tot_Rept_Positions_Short_All  Swap_Positions_Long_All  \\\n",
       "1                         611450                    49652   \n",
       "5                         614798                    44445   \n",
       "8                         639206                    42442   \n",
       "9                         634603                    38033   \n",
       "13                        635564                    24175   \n",
       "\n",
       "    Swap__Positions_Short_All  Change_in_M_Money_Long_All  \\\n",
       "1                       67586                      1437.0   \n",
       "5                       70483                     -1811.0   \n",
       "8                       63008                      3285.0   \n",
       "9                       61425                      8238.0   \n",
       "13                      71649                     27561.0   \n",
       "\n",
       "    Change_in_M_Money_Short_All  \n",
       "1                        2763.0  \n",
       "5                       -1716.0  \n",
       "8                       -3193.0  \n",
       "9                       -1721.0  \n",
       "13                      -5012.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load combined CFTC dataset\n",
    "cot_df = pd.read_csv(\"cot_combined_2012_2024.csv\", parse_dates=[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "\n",
    "# Standardize commodity names to simplify downstream merges\n",
    "cot_df[\"Market_and_Exchange_Names\"] = cot_df[\"Market_and_Exchange_Names\"].replace({\n",
    "    \"GOLD - COMMODITY EXCHANGE INC.\": \"Gold\",\n",
    "    \"SILVER - COMMODITY EXCHANGE INC.\": \"Silver\",\n",
    "    \"COPPER - COMMODITY EXCHANGE INC.\": \"Copper\",\n",
    "    \"COPPER- #1 - COMMODITY EXCHANGE INC.\": \"Copper\",\n",
    "    \"COPPER-GRADE #1 - COMMODITY EXCHANGE INC.\": \"Copper\"\n",
    "})\n",
    "\n",
    "# Split into separate DataFrames\n",
    "cot_gold = cot_df[cot_df[\"Market_and_Exchange_Names\"] == \"Gold\"].copy()\n",
    "cot_silver = cot_df[cot_df[\"Market_and_Exchange_Names\"] == \"Silver\"].copy()\n",
    "cot_copper = cot_df[cot_df[\"Market_and_Exchange_Names\"] == \"Copper\"].copy()\n",
    "\n",
    "# Save each one\n",
    "cot_gold.to_csv(\"cot_gold_2012_2024.csv\", index=False)\n",
    "cot_silver.to_csv(\"cot_silver_2012_2024.csv\", index=False)\n",
    "cot_copper.to_csv(\"cot_copper_2012_2024.csv\", index=False)\n",
    "\n",
    "# Preview gold\n",
    "cot_gold.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging by Commodity, YF and COT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shaping the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gold/Gold_YF_2012_2024_cleaned.csv'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Gold YF file that contains extra rows and unnamed headers\n",
    "gold_yf = pd.read_csv(\"Gold_YF_2012_2024.csv\", skiprows=2)\n",
    "\n",
    "# Rename columns properly\n",
    "gold_yf.columns = [\n",
    "    \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"SMA_7\", \"SMA_30\", \"RSI_14\", \n",
    "    \"MACD\", \"BB_Width\", \"Volume_Zscore\", \"Pct_Change\"\n",
    "]\n",
    "\n",
    "# Convert date to datetime and set index\n",
    "gold_yf[\"Date\"] = pd.to_datetime(gold_yf[\"Date\"])\n",
    "gold_yf.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Save cleaned file\n",
    "cleaned_yf_path = \"gold/Gold_YF_2012_2024_cleaned.csv\"\n",
    "gold_yf.to_csv(cleaned_yf_path)\n",
    "\n",
    "cleaned_yf_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge GC=F with COT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/wrgs7dkx0h5ftr4gsr51y6xm0000gn/T/ipykernel_7777/2389388134.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_gold = merged_gold.drop(columns=[\"Market_and_Exchange_Names\"]).fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "gold_yf = pd.read_csv(\"gold/Gold_YF_2012_2024_cleaned.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "cot_gold = pd.read_csv(\"cot_gold_2012_2024.csv\", parse_dates=[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "cot_gold.set_index(\"As_of_Date_In_Form_YYMMDD\", inplace=True)\n",
    "cot_gold.index.name = \"Date\"\n",
    "\n",
    "# Merge the two datasets on Date\n",
    "merged_gold = gold_yf.merge(cot_gold, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "merged_gold = merged_gold.drop(columns=[\"Market_and_Exchange_Names\"]).fillna(method=\"ffill\")\n",
    "\n",
    "merged_path = \"gold/Gold_YF_COT_merged_final.csv\"\n",
    "merged_gold.to_csv(merged_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gold/Gold_YF_COT_GLD_M.csv'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the raw GLD CSV and fix header rows before merging\n",
    "gld_raw = pd.read_csv(\"GLD_2012_2024_OHLCV.csv\", skiprows=2)\n",
    "\n",
    "gld_raw.columns = [\"Date\", \"GLD_Open\", \"GLD_High\", \"GLD_Low\", \"GLD_Close\", \"GLD_Volume\"]\n",
    "gld_raw[\"Date\"] = pd.to_datetime(gld_raw[\"Date\"])\n",
    "gld_raw.set_index(\"Date\", inplace=True)\n",
    "\n",
    "gold_merged = pd.read_csv(\"gold/Gold_YF_COT_merged_final.csv\", parse_dates=[\"Date\"])\n",
    "gold_merged.set_index(\"Date\", inplace=True)\n",
    "\n",
    "final_named_merged = gold_merged.merge(gld_raw, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# Save final clean output\n",
    "final_named_path = \"gold/Gold_YF_COT_GLD_M.csv\"\n",
    "final_named_merged.to_csv(final_named_path)\n",
    "\n",
    "final_named_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GC=F,GLD, CoT with forward filling and FRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First month of 2012 is missing vlaues due to release of the macroeconomic indicators in 2011(update quaterly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gold/Gold_All_M.csv'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your main dataset\n",
    "gold_df = pd.read_csv(\"gold/Gold_YF_COT_GLD_M.csv\", parse_dates=[\"Date\"])\n",
    "gold_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Merge and save\n",
    "merged = gold_df.merge(macro_combined, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "cols_to_ffill = ['House_Price_Index', 'GDP_Quarterly', 'Net_Exports_GS']\n",
    "merged[cols_to_ffill] = merged[cols_to_ffill].ffill()\n",
    "\n",
    "# Check that there are no more missing values in those columns\n",
    "merged[cols_to_ffill].isnull().sum()\n",
    "\n",
    "# Save the forward-filled (only) version to a new file\n",
    "output_path_ffill_only = \"gold/Gold_All_M.csv\"\n",
    "merged.to_csv(output_path_ffill_only, index=True)\n",
    "\n",
    "output_path_ffill_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with SLV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shaping the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silver_yf = pd.read_csv(\"Silver_YF_2012_2024.csv\", skiprows=2)\n",
    "\n",
    "# Rename columns to match structure used in gold\n",
    "silver_yf.columns = [\n",
    "    \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"SMA_7\", \"SMA_30\", \"RSI_14\", \n",
    "    \"MACD\", \"BB_Width\", \"Volume_Zscore\", \"Pct_Change\"\n",
    "]\n",
    "\n",
    "# Convert 'Date' column to datetime and set as index\n",
    "silver_yf[\"Date\"] = pd.to_datetime(silver_yf[\"Date\"])\n",
    "silver_yf.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Save cleaned Silver dataset\n",
    "cleaned_silver_path = \"silver/Silver_YF_2012_2024_cleaned.csv\"\n",
    "silver_yf.to_csv(cleaned_silver_path)\n",
    "\n",
    "print(f\" Cleaned Silver YF saved at: {cleaned_silver_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with COT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silver_yf = pd.read_csv(\"silver/Silver_YF_2012_2024_cleaned.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "cot_silver = pd.read_csv(\"cot_silver_2012_2024.csv\", parse_dates=[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "cot_silver.set_index(\"As_of_Date_In_Form_YYMMDD\", inplace=True)\n",
    "cot_silver.index.name = \"Date\"\n",
    "\n",
    "# 3. Merge on Date\n",
    "merged_silver = silver_yf.merge(cot_silver, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# 4. Clean: drop unnecessary column and forward fill missing values\n",
    "merged_silver = merged_silver.drop(columns=[\"Market_and_Exchange_Names\"]).fillna(method=\"ffill\")\n",
    "\n",
    "# 5. Save the merged dataset\n",
    "merged_path = \"silver/Silver_YF_COT_merged_final.csv\"\n",
    "merged_silver.to_csv(merged_path)\n",
    "\n",
    "print(f\" Silver + COT merged and saved at {merged_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge YF, COT with SLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slv_raw = yf.download(\"SLV\", start=\"2012-01-01\", end=\"2024-12-31\", interval=\"1d\")\n",
    "slv_raw = slv_raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "slv_raw.reset_index(inplace=True)\n",
    "slv_raw.columns = [\"Date\", \"SLV_Open\", \"SLV_High\", \"SLV_Low\", \"SLV_Close\", \"SLV_Volume\"]\n",
    "slv_raw[\"Date\"] = pd.to_datetime(slv_raw[\"Date\"])\n",
    "slv_raw.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Step 2: Load already merged Silver + COT dataset\n",
    "silver_merged = pd.read_csv(\"silver/Silver_YF_COT_merged_final.csv\", parse_dates=[\"Date\"])\n",
    "silver_merged.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Step 3: Merge SLV into Silver dataset\n",
    "silver_final = silver_merged.merge(slv_raw, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# Step 4: Save final file\n",
    "final_path = \"silver/Silver_YF_COT_SLV_M.csv\"\n",
    "silver_final.to_csv(final_path)\n",
    "\n",
    "print(f\" Final Silver dataset with SLV saved at: {final_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "macro = pd.read_csv(\"fred_ind/macro_ind_2012_2024.csv\", parse_dates=[\"Date\"])\n",
    "macro.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Load your full Silver dataset (Silver + COT + SLV)\n",
    "silver_df = pd.read_csv(\"silver/Silver_YF_COT_SLV_M.csv\", parse_dates=[\"Date\"])\n",
    "silver_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Merge macro indicators\n",
    "merged = silver_df.merge(macro, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# Forward-fill slow-moving macro variables\n",
    "cols_to_ffill = ['House_Price_Index', 'GDP_Quarterly', 'Net_Exports_GS']\n",
    "merged[cols_to_ffill] = merged[cols_to_ffill].ffill()\n",
    "\n",
    "# Save final enriched file\n",
    "output_path = \"silver/Silver_All_M.csv\"\n",
    "merged.to_csv(output_path)\n",
    "\n",
    "print(f\" Final Silver dataset saved with macro indicators: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"silver/Silver_All_M.csv\", parse_dates=[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# === 1. VWAP ===\n",
    "df[\"VWAP\"] = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
    "\n",
    "# === 2. COT Ratios ===\n",
    "df[\"MM_Long_Ratio\"] = df[\"M_Money_Positions_Long_ALL\"] / df[\"Open_Interest_All\"]\n",
    "df[\"MM_Short_Ratio\"] = df[\"M_Money_Positions_Short_ALL\"] / df[\"Open_Interest_All\"]\n",
    "\n",
    "df[\"Dealer_Long_Ratio\"] = df[\"Swap_Positions_Long_All\"] / df[\"Open_Interest_All\"]\n",
    "df[\"Dealer_Short_Ratio\"] = df[\"Swap__Positions_Short_All\"] / df[\"Open_Interest_All\"]\n",
    "\n",
    "\n",
    "# Lag features\n",
    "df[\"Close_lag_1\"] = df[\"Close\"].shift(1)\n",
    "df[\"Close_lag_3\"] = df[\"Close\"].shift(3)\n",
    "df[\"Close_lag_7\"] = df[\"Close\"].shift(7)\n",
    "\n",
    "# Moving Averages (on Close)\n",
    "df[\"MA_5\"] = df[\"Close\"].rolling(window=5).mean()\n",
    "df[\"MA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
    "df[\"MA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "\n",
    "# Rolling Standard Deviation (volatility)\n",
    "df[\"STD_5\"] = df[\"Close\"].rolling(window=5).std()\n",
    "df[\"STD_10\"] = df[\"Close\"].rolling(window=10).std()\n",
    "\n",
    "# Momentum\n",
    "df[\"Pct_Change_1\"] = df[\"Close\"].pct_change(1)\n",
    "df[\"Pct_Change_3\"] = df[\"Close\"].pct_change(3)\n",
    "\n",
    "# Drop NaNs caused by rolling/lags\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Save the new dataset\n",
    "df.to_csv(\"silver/Silver_All_M1.csv\")\n",
    "print(\" Feature engineered dataset saved as 'Silver_All_M_Features.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw Copper YF file (with extra headers)\n",
    "copper_yf = pd.read_csv(\"Copper_YF_2012_2024.csv\", skiprows=2)\n",
    "\n",
    "# Rename columns to match Gold/Silver structure\n",
    "copper_yf.columns = [\n",
    "    \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"SMA_7\", \"SMA_30\", \"RSI_14\", \n",
    "    \"MACD\", \"BB_Width\", \"Volume_Zscore\", \"Pct_Change\"\n",
    "]\n",
    "\n",
    "# Convert Date to datetime and set as index\n",
    "copper_yf[\"Date\"] = pd.to_datetime(copper_yf[\"Date\"])\n",
    "copper_yf.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Save cleaned Copper dataset\n",
    "cleaned_copper_path = \"copper/Copper_YF_2012_2024_cleaned.csv\"\n",
    "copper_yf.to_csv(cleaned_copper_path)\n",
    "\n",
    "print(f\" Cleaned Copper YF saved at: {cleaned_copper_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "copper_yf = pd.read_csv(\"copper/Copper_YF_2012_2024_cleaned.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "# Step 2: Load Copper COT data\n",
    "cot_copper = pd.read_csv(\"cot_copper_2012_2024.csv\", parse_dates=[\"As_of_Date_In_Form_YYMMDD\"])\n",
    "cot_copper.set_index(\"As_of_Date_In_Form_YYMMDD\", inplace=True)\n",
    "cot_copper.index.name = \"Date\"\n",
    "\n",
    "# Step 3: Merge on date and forward-fill COT values\n",
    "merged_copper = copper_yf.merge(cot_copper, how=\"left\", left_index=True, right_index=True)\n",
    "merged_copper = merged_copper.drop(columns=[\"Market_and_Exchange_Names\"]).fillna(method=\"ffill\")\n",
    "\n",
    "# Step 4: Save the merged dataset\n",
    "merged_copper_path = \"copper/Copper_YF_COT_merged_final.csv\"\n",
    "merged_copper.to_csv(merged_copper_path)\n",
    "\n",
    "print(f\" Merged Copper + COT saved at: {merged_copper_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "macro = pd.read_csv(\"fred_ind/macro_ind_2012_2024.csv\", parse_dates=[\"Date\"])\n",
    "macro.set_index(\"Date\", inplace=True)\n",
    "\n",
    "\n",
    "# Step 3: Load your Copper + COT merged dataset\n",
    "copper_df = pd.read_csv(\"copper/Copper_YF_COT_merged_final.csv\", parse_dates=[\"Date\"])\n",
    "copper_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Step 4: Merge all macro sources\n",
    "merged = copper_df.merge(macro, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# Step 5: Forward-fill slower-moving indicators\n",
    "cols_to_ffill = ['House_Price_Index', 'GDP_Quarterly', 'Net_Exports_GS']\n",
    "merged[cols_to_ffill] = merged[cols_to_ffill].ffill()\n",
    "\n",
    "# Step 6: Save final Copper dataset\n",
    "final_path = \"copper/Copper_All_M.csv\"\n",
    "merged.to_csv(final_path)\n",
    "\n",
    "print(f\" Final Copper dataset saved with FRED: {final_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "copx = yf.download(\"COPX\", start=\"2012-01-01\", end=\"2024-12-31\", interval=\"1d\")\n",
    "\n",
    "# Step 2: Clean and rename COPX columns\n",
    "copx = copx[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "copx.reset_index(inplace=True)\n",
    "copx.columns = [\"Date\", \"COPX_Open\", \"COPX_High\", \"COPX_Low\", \"COPX_Close\", \"COPX_Volume\"]\n",
    "copx[\"Date\"] = pd.to_datetime(copx[\"Date\"])\n",
    "copx.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Step 3: Load the Copper dataset with all macro + COT merged\n",
    "copper_df = pd.read_csv(\"copper/Copper_All_M.csv\", parse_dates=[\"Date\"])\n",
    "copper_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Step 4: Merge with COPX data\n",
    "copper_final = copper_df.merge(copx, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "# Step 5: Save final version\n",
    "final_path = \"copper/Copper_All_M.csv\"\n",
    "copper_final.to_csv(final_path)\n",
    "\n",
    "print(f\" Final Copper dataset with COPX saved at: {final_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After changing the time horizon, First I fetched the whole data again, dropped COT, added SP500, VIX and GPR indicies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ending _auto for datasets, targets usage for NeuralForecast libraries. Each of them has additional column with unique_id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/gold_fixed_auto.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gold \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/gold_fixed_auto.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/gold_fixed_auto.csv'"
     ]
    }
   ],
   "source": [
    "gold = pd.read_csv(\"data/gold_fixed_auto.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
